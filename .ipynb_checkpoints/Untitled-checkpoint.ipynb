{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd3ad6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\keywords.csv\n",
      ".\\movies_metadata.csv\n",
      ".\\Untitled.ipynb\n",
      ".\\.ipynb_checkpoints\\Untitled-checkpoint.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('.'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852cf2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a9f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the metadata of movies\n",
    "df1 = pd.read_csv('movies_metadata.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09d0560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview  ... release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a60167",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1[['title', 'tagline', 'original_title', 'overview', 'genres']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "023d239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             title  \\\n",
      "0                        Toy Story   \n",
      "1                          Jumanji   \n",
      "2                 Grumpier Old Men   \n",
      "3                Waiting to Exhale   \n",
      "4      Father of the Bride Part II   \n",
      "...                            ...   \n",
      "45461                       Subdue   \n",
      "45462          Century of Birthing   \n",
      "45463                     Betrayal   \n",
      "45464             Satan Triumphant   \n",
      "45465                     Queerama   \n",
      "\n",
      "                                                 tagline  \\\n",
      "0                                                    NaN   \n",
      "1              Roll the dice and unleash the excitement!   \n",
      "2      Still Yelling. Still Fighting. Still Ready for...   \n",
      "3      Friends are the people who let you be yourself...   \n",
      "4      Just When His World Is Back To Normal... He's ...   \n",
      "...                                                  ...   \n",
      "45461         Rising and falling between a man and woman   \n",
      "45462                                                NaN   \n",
      "45463                             A deadly game of wits.   \n",
      "45464                                                NaN   \n",
      "45465                                                NaN   \n",
      "\n",
      "                    original_title  \\\n",
      "0                        Toy Story   \n",
      "1                          Jumanji   \n",
      "2                 Grumpier Old Men   \n",
      "3                Waiting to Exhale   \n",
      "4      Father of the Bride Part II   \n",
      "...                            ...   \n",
      "45461                      رگ خواب   \n",
      "45462          Siglo ng Pagluluwal   \n",
      "45463                     Betrayal   \n",
      "45464          Satana likuyushchiy   \n",
      "45465                     Queerama   \n",
      "\n",
      "                                                overview  \\\n",
      "0      Led by Woody, Andy's toys live happily in his ...   \n",
      "1      When siblings Judy and Peter discover an encha...   \n",
      "2      A family wedding reignites the ancient feud be...   \n",
      "3      Cheated on, mistreated and stepped on, the wom...   \n",
      "4      Just when George Banks has recovered from his ...   \n",
      "...                                                  ...   \n",
      "45461        Rising and falling between a man and woman.   \n",
      "45462  An artist struggles to finish his work while a...   \n",
      "45463  When one of her hits goes wrong, a professiona...   \n",
      "45464  In a small town live two brothers, one a minis...   \n",
      "45465  50 years after decriminalisation of homosexual...   \n",
      "\n",
      "                                                  genres  \n",
      "0      [{'id': 16, 'name': 'Animation'}, {'id': 35, '...  \n",
      "1      [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...  \n",
      "2      [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...  \n",
      "3      [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...  \n",
      "4                         [{'id': 35, 'name': 'Comedy'}]  \n",
      "...                                                  ...  \n",
      "45461  [{'id': 18, 'name': 'Drama'}, {'id': 10751, 'n...  \n",
      "45462                      [{'id': 18, 'name': 'Drama'}]  \n",
      "45463  [{'id': 28, 'name': 'Action'}, {'id': 18, 'nam...  \n",
      "45464                                                 []  \n",
      "45465                                                 []  \n",
      "\n",
      "[45466 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72ecf24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting `title` as the index\n",
    "df.set_index('title',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9114cd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tagline           25054\n",
       "original_title        0\n",
       "overview            954\n",
       "genres                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d736f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "df.dropna(subset = ['overview'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b37767a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "df['genres'] = df['genres'].apply(literal_eval).apply(lambda x: [i['name'] for i in x] \n",
    "                                                                   if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "142939c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only those rows which have an actual genre\n",
    "genre_present = df['genres'] != '[]'\n",
    "\n",
    "# Series of the genres present in the movies_metadata\n",
    "genres = df['genres'][genre_present]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1023b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "labels = mlb.fit_transform(genres)\n",
    "label_classes = mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "912e844f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Action', 'Adventure', 'Animation', 'Aniplex', 'BROSTA TV',\n",
       "       'Carousel Productions', 'Comedy', 'Crime', 'Documentary', 'Drama',\n",
       "       'Family', 'Fantasy', 'Foreign', 'GoHands', 'History', 'Horror',\n",
       "       'Mardock Scramble Production Committee', 'Music', 'Mystery',\n",
       "       'Odyssey Media', 'Pulser Productions', 'Rogue State', 'Romance',\n",
       "       'Science Fiction', 'Sentai Filmworks', 'TV Movie',\n",
       "       'Telescene Film Group Productions', 'The Cartel', 'Thriller',\n",
       "       'Vision View Entertainment', 'War', 'Western'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99bacfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.DataFrame(labels, columns=label_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db262e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = {}\n",
    "for x in label_classes :\n",
    "    val.update({x:label_data[x].value_counts()[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4dc2d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_val = sorted(val.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "477b9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pd = pd.DataFrame.from_dict(sorted_val, orient='columns')\n",
    "val_pd.rename(columns={0: \"Genre\", 1: \"Count\"}, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57cd4890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drama</td>\n",
       "      <td>20023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comedy</td>\n",
       "      <td>12806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thriller</td>\n",
       "      <td>7586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romance</td>\n",
       "      <td>6673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Action</td>\n",
       "      <td>6565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Horror</td>\n",
       "      <td>4660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Crime</td>\n",
       "      <td>4269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Documentary</td>\n",
       "      <td>3886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adventure</td>\n",
       "      <td>3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Science Fiction</td>\n",
       "      <td>3028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Family</td>\n",
       "      <td>2732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mystery</td>\n",
       "      <td>2451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fantasy</td>\n",
       "      <td>2290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Animation</td>\n",
       "      <td>1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Foreign</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Music</td>\n",
       "      <td>1588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>History</td>\n",
       "      <td>1379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>War</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Western</td>\n",
       "      <td>1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TV Movie</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Aniplex</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BROSTA TV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Carousel Productions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GoHands</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mardock Scramble Production Committee</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Odyssey Media</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Pulser Productions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rogue State</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sentai Filmworks</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Telescene Film Group Productions</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The Cartel</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Vision View Entertainment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Genre  Count\n",
       "0                                   Drama  20023\n",
       "1                                  Comedy  12806\n",
       "2                                Thriller   7586\n",
       "3                                 Romance   6673\n",
       "4                                  Action   6565\n",
       "5                                  Horror   4660\n",
       "6                                   Crime   4269\n",
       "7                             Documentary   3886\n",
       "8                               Adventure   3470\n",
       "9                         Science Fiction   3028\n",
       "10                                 Family   2732\n",
       "11                                Mystery   2451\n",
       "12                                Fantasy   2290\n",
       "13                              Animation   1920\n",
       "14                                Foreign   1599\n",
       "15                                  Music   1588\n",
       "16                                History   1379\n",
       "17                                    War   1310\n",
       "18                                Western   1035\n",
       "19                               TV Movie    751\n",
       "20                                Aniplex      1\n",
       "21                              BROSTA TV      1\n",
       "22                   Carousel Productions      1\n",
       "23                                GoHands      1\n",
       "24  Mardock Scramble Production Committee      1\n",
       "25                          Odyssey Media      1\n",
       "26                     Pulser Productions      1\n",
       "27                            Rogue State      1\n",
       "28                       Sentai Filmworks      1\n",
       "29       Telescene Film Group Productions      1\n",
       "30                             The Cartel      1\n",
       "31              Vision View Entertainment      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e61923a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Drama', 20023),\n",
       " ('Comedy', 12806),\n",
       " ('Thriller', 7586),\n",
       " ('Romance', 6673),\n",
       " ('Action', 6565),\n",
       " ('Horror', 4660),\n",
       " ('Crime', 4269),\n",
       " ('Documentary', 3886),\n",
       " ('Adventure', 3470),\n",
       " ('Science Fiction', 3028)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_counts = sorted(val.items(), key=lambda kv: kv[1], reverse=True)[0:10] # Selecting the first 10 genres.\n",
    "dummy_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2858356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Comprehension\n",
    "genre_counts = [i[0] for i in dummy_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "262d3921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Drama',\n",
       " 'Comedy',\n",
       " 'Thriller',\n",
       " 'Romance',\n",
       " 'Action',\n",
       " 'Horror',\n",
       " 'Crime',\n",
       " 'Documentary',\n",
       " 'Adventure',\n",
       " 'Science Fiction']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d7b48d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiLabelBinarizer(classes=[&#x27;Drama&#x27;, &#x27;Comedy&#x27;, &#x27;Thriller&#x27;, &#x27;Romance&#x27;, &#x27;Action&#x27;,\n",
       "                             &#x27;Horror&#x27;, &#x27;Crime&#x27;, &#x27;Documentary&#x27;, &#x27;Adventure&#x27;,\n",
       "                             &#x27;Science Fiction&#x27;])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiLabelBinarizer</label><div class=\"sk-toggleable__content\"><pre>MultiLabelBinarizer(classes=[&#x27;Drama&#x27;, &#x27;Comedy&#x27;, &#x27;Thriller&#x27;, &#x27;Romance&#x27;, &#x27;Action&#x27;,\n",
       "                             &#x27;Horror&#x27;, &#x27;Crime&#x27;, &#x27;Documentary&#x27;, &#x27;Adventure&#x27;,\n",
       "                             &#x27;Science Fiction&#x27;])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiLabelBinarizer(classes=['Drama', 'Comedy', 'Thriller', 'Romance', 'Action',\n",
       "                             'Horror', 'Crime', 'Documentary', 'Adventure',\n",
       "                             'Science Fiction'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_genres = MultiLabelBinarizer(classes = genre_counts) \n",
    "# 'genre_counts' is the final list of genres that will be used for futher training ot model\n",
    "\n",
    "final_genres.fit(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62c9032a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:900: UserWarning: unknown class(es) ['Animation', 'Aniplex', 'BROSTA TV', 'Carousel Productions', 'Family', 'Fantasy', 'Foreign', 'GoHands', 'History', 'Mardock Scramble Production Committee', 'Music', 'Mystery', 'Odyssey Media', 'Pulser Productions', 'Rogue State', 'Sentai Filmworks', 'TV Movie', 'Telescene Film Group Productions', 'The Cartel', 'Vision View Entertainment', 'War', 'Western'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Dependent Variable\n",
    "y = final_genres.transform(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a897d1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Drama', 'Comedy', 'Thriller', 'Romance', 'Action', 'Horror',\n",
       "       'Crime', 'Documentary', 'Adventure', 'Science Fiction'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_genres.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71f25f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3508b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent Variable\n",
    "X_overview = df['overview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5af53ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Toy Story                      Led by Woody, Andy's toys live happily in his ...\n",
       "Jumanji                        When siblings Judy and Peter discover an encha...\n",
       "Grumpier Old Men               A family wedding reignites the ancient feud be...\n",
       "Waiting to Exhale              Cheated on, mistreated and stepped on, the wom...\n",
       "Father of the Bride Part II    Just when George Banks has recovered from his ...\n",
       "                                                     ...                        \n",
       "Subdue                               Rising and falling between a man and woman.\n",
       "Century of Birthing            An artist struggles to finish his work while a...\n",
       "Betrayal                       When one of her hits goes wrong, a professiona...\n",
       "Satan Triumphant               In a small town live two brothers, one a minis...\n",
       "Queerama                       50 years after decriminalisation of homosexual...\n",
       "Name: overview, Length: 44512, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02af1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features = 4000, stop_words = 'english', lowercase = True)\n",
    "\n",
    "X_overview_vec = vectorizer.fit_transform(X_overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1b040b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X_overview_vec, y, test_size=0.2, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95ae1ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<35609x4000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 694375 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c7337b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b346f0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((35609, 4000), (35609, 10))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5432da29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8903, 4000), (8903, 10))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b32df32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters found: {'estimator__min_samples_split': 2, 'estimator__min_samples_leaf': 1, 'estimator__max_features': 'sqrt', 'estimator__max_depth': None}\n",
      "[[[0.33177315 0.66822685]\n",
      "  [0.415      0.585     ]\n",
      "  [0.605      0.395     ]\n",
      "  ...\n",
      "  [0.72       0.28      ]\n",
      "  [0.695      0.305     ]\n",
      "  [0.82236472 0.17763528]]\n",
      "\n",
      " [[0.79011931 0.20988069]\n",
      "  [0.75       0.25      ]\n",
      "  [0.92       0.08      ]\n",
      "  ...\n",
      "  [0.835      0.165     ]\n",
      "  [0.64       0.36      ]\n",
      "  [0.91351852 0.08648148]]\n",
      "\n",
      " [[0.93351457 0.06648543]\n",
      "  [0.99       0.01      ]\n",
      "  [0.8        0.2       ]\n",
      "  ...\n",
      "  [0.955      0.045     ]\n",
      "  [0.835      0.165     ]\n",
      "  [0.84980769 0.15019231]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.58       0.42      ]\n",
      "  [0.975      0.025     ]\n",
      "  [0.935      0.065     ]\n",
      "  ...\n",
      "  [0.705      0.295     ]\n",
      "  [0.775      0.225     ]\n",
      "  [1.         0.        ]]\n",
      "\n",
      " [[1.         0.        ]\n",
      "  [0.975      0.025     ]\n",
      "  [1.         0.        ]\n",
      "  ...\n",
      "  [0.825      0.175     ]\n",
      "  [0.965      0.035     ]\n",
      "  [0.865      0.135     ]]\n",
      "\n",
      " [[1.         0.        ]\n",
      "  [0.995      0.005     ]\n",
      "  [1.         0.        ]\n",
      "  ...\n",
      "  [0.995      0.005     ]\n",
      "  [0.975      0.025     ]\n",
      "  [0.56       0.44      ]]]\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Drama       0.64      0.67      0.66      3975\n",
      "         Comedy       0.75      0.25      0.38      2573\n",
      "       Thriller       0.64      0.07      0.12      1505\n",
      "        Romance       0.64      0.08      0.15      1352\n",
      "         Action       0.70      0.11      0.18      1347\n",
      "         Horror       0.76      0.20      0.32       941\n",
      "          Crime       0.51      0.05      0.09       837\n",
      "    Documentary       0.79      0.41      0.54       740\n",
      "      Adventure       0.52      0.02      0.04       726\n",
      "Science Fiction       0.80      0.26      0.40       619\n",
      "\n",
      "      micro avg       0.67      0.30      0.42     14615\n",
      "      macro avg       0.67      0.21      0.29     14615\n",
      "   weighted avg       0.67      0.30      0.36     14615\n",
      "    samples avg       0.79      0.41      0.54     14615\n",
      "\n",
      "\n",
      "Hamming Loss:\n",
      "0.13881837582837245\n",
      "\n",
      "F1 Score:\n",
      "0.41523539153063643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, hamming_loss, f1_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Chuẩn bị dữ liệu - Đoạn mã chuẩn bị dữ liệu đầy đủ ở trên\n",
    "# Định nghĩa siêu tham số bạn muốn tinh chỉnh và phạm vi của chúng\n",
    "param_dist1 = {\n",
    "    'estimator__max_depth': [None, 10],\n",
    "    'estimator__min_samples_split': [2, 5],\n",
    "    'estimator__min_samples_leaf': [1, 2, 4],\n",
    "    'estimator__max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Tạo một bộ phân phối ngẫu nhiên cho RandomizedSearchCV\n",
    "random_search1 = RandomizedSearchCV(\n",
    "    estimator=MultiOutputClassifier(RandomForestClassifier(n_estimators=200, random_state=42)),\n",
    "    param_distributions=param_dist1,\n",
    "    n_iter=10,  # Số lượng lần lặp để tìm kiếm ngẫu nhiên\n",
    "    cv=3,  # Số lượng gấp ba phân chia chéo\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Tiến hành tìm kiếm ngẫu nhiên siêu tham số tốt nhất\n",
    "random_search1.fit(X_train, y_train)\n",
    "\n",
    "# In ra siêu tham số tốt nhất đã tìm được\n",
    "print(\"Best parameters found:\", random_search1.best_params_)\n",
    "model1 = random_search1.best_estimator_\n",
    "model1.fit(X_train, y_train)\n",
    "# Dự đoán nhãn\n",
    "y_pred_proba1 = model1.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# Chuyển đổi xác suất thành nhãn dự đoán\n",
    "y_pred1 = np.zeros_like(y_test)\n",
    "\n",
    "# y_pred_proba1 là một danh sách của các mảng xác suất cho từng nhãn\n",
    "# Chuyển đổi y_pred_proba1 sang định dạng numpy để dễ thao tác hơn\n",
    "y_pred_proba1 = np.array(y_pred_proba1)\n",
    "\n",
    "print(y_pred_proba1)\n",
    "\n",
    "# Lấy số lượng nhãn từ num_labels_test\n",
    "for i in range(len(y_test)):\n",
    "    # Lấy xác suất dự đoán cho mẫu thứ i\n",
    "    proba1 = np.array([y_pred_proba1[j][:, 1][i] for j in range(len(y_pred_proba1))])\n",
    "    top_k_indices1 = np.where(proba1 > 0.5)[0]\n",
    "    if len(top_k_indices1) == 0:\n",
    "        y_pred1[i, top_k_indices1] = 0\n",
    "    else:\n",
    "        y_pred1[i, top_k_indices1] = 1\n",
    "# Đánh giá mô hình\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred1, target_names=genre_counts, zero_division=1))\n",
    "\n",
    "print(\"\\nHamming Loss:\")\n",
    "print(hamming_loss(y_test, y_pred1))\n",
    "\n",
    "print(\"\\nF1 Score:\")\n",
    "print(f1_score(y_test, y_pred1, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6557c0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.63230497\n",
      "Iteration 2, loss = 0.54752470\n",
      "Iteration 3, loss = 0.52476160\n",
      "Iteration 4, loss = 0.51552596\n",
      "Iteration 5, loss = 0.50972044\n",
      "Iteration 6, loss = 0.50483410\n",
      "Iteration 7, loss = 0.50086252\n",
      "Iteration 8, loss = 0.49706312\n",
      "Iteration 9, loss = 0.49289319\n",
      "Iteration 10, loss = 0.48834643\n",
      "Iteration 11, loss = 0.48328113\n",
      "Iteration 12, loss = 0.47816693\n",
      "Iteration 13, loss = 0.47213936\n",
      "Iteration 14, loss = 0.46523065\n",
      "Iteration 15, loss = 0.45797632\n",
      "Iteration 16, loss = 0.44974537\n",
      "Iteration 17, loss = 0.44111095\n",
      "Iteration 18, loss = 0.43096788\n",
      "Iteration 19, loss = 0.42015781\n",
      "Iteration 20, loss = 0.40853829\n",
      "Iteration 21, loss = 0.39540456\n",
      "Iteration 22, loss = 0.38167012\n",
      "Iteration 23, loss = 0.36676907\n",
      "Iteration 24, loss = 0.35067983\n",
      "Iteration 25, loss = 0.33332305\n",
      "Iteration 26, loss = 0.31575656\n",
      "Iteration 27, loss = 0.29666986\n",
      "Iteration 28, loss = 0.27673978\n",
      "Iteration 29, loss = 0.25769627\n",
      "Iteration 30, loss = 0.23799290\n",
      "Iteration 31, loss = 0.21756634\n",
      "Iteration 32, loss = 0.19881750\n",
      "Iteration 33, loss = 0.17997967\n",
      "Iteration 34, loss = 0.16290043\n",
      "Iteration 35, loss = 0.14695336\n",
      "Iteration 36, loss = 0.13186495\n",
      "Iteration 37, loss = 0.11825559\n",
      "Iteration 38, loss = 0.10549624\n",
      "Iteration 39, loss = 0.09496631\n",
      "Iteration 40, loss = 0.08449353\n",
      "Iteration 41, loss = 0.07560407\n",
      "Iteration 42, loss = 0.06800920\n",
      "Iteration 43, loss = 0.06101294\n",
      "Iteration 44, loss = 0.05459094\n",
      "Iteration 45, loss = 0.04917527\n",
      "Iteration 46, loss = 0.04449419\n",
      "Iteration 47, loss = 0.04016753\n",
      "Iteration 48, loss = 0.03641086\n",
      "Iteration 49, loss = 0.03326637\n",
      "Iteration 50, loss = 0.03040852\n",
      "Iteration 51, loss = 0.02780175\n",
      "Iteration 52, loss = 0.02555094\n",
      "Iteration 53, loss = 0.02350886\n",
      "Iteration 54, loss = 0.02175756\n",
      "Iteration 55, loss = 0.02038703\n",
      "Iteration 56, loss = 0.01882959\n",
      "Iteration 57, loss = 0.01767108\n",
      "Iteration 58, loss = 0.01647407\n",
      "Iteration 59, loss = 0.01562589\n",
      "Iteration 60, loss = 0.01493844\n",
      "Iteration 61, loss = 0.01400462\n",
      "Iteration 62, loss = 0.01327179\n",
      "Iteration 63, loss = 0.01269466\n",
      "Iteration 64, loss = 0.01206161\n",
      "Iteration 65, loss = 0.01141307\n",
      "Iteration 66, loss = 0.01127206\n",
      "Iteration 67, loss = 0.01060382\n",
      "Iteration 68, loss = 0.01030771\n",
      "Iteration 69, loss = 0.01014921\n",
      "Iteration 70, loss = 0.00999954\n",
      "Iteration 71, loss = 0.00957811\n",
      "Iteration 72, loss = 0.00929234\n",
      "Iteration 73, loss = 0.00888117\n",
      "Iteration 74, loss = 0.00896672\n",
      "Iteration 75, loss = 0.00871208\n",
      "Iteration 76, loss = 0.00877675\n",
      "Iteration 77, loss = 0.00832278\n",
      "Iteration 78, loss = 0.00828480\n",
      "Iteration 79, loss = 0.00810532\n",
      "Iteration 80, loss = 0.00822859\n",
      "Iteration 81, loss = 0.00798311\n",
      "Iteration 82, loss = 0.00821541\n",
      "Iteration 83, loss = 0.00785047\n",
      "Iteration 84, loss = 0.00787153\n",
      "Iteration 85, loss = 0.00789201\n",
      "Iteration 86, loss = 0.00777272\n",
      "Iteration 87, loss = 0.00770162\n",
      "Iteration 88, loss = 0.00751554\n",
      "Iteration 89, loss = 0.00764083\n",
      "Iteration 90, loss = 0.00805446\n",
      "Iteration 91, loss = 0.00761596\n",
      "Iteration 92, loss = 0.00771808\n",
      "Iteration 93, loss = 0.00759761\n",
      "Iteration 94, loss = 0.00757055\n",
      "Iteration 95, loss = 0.00769815\n",
      "Iteration 96, loss = 0.00733108\n",
      "Iteration 97, loss = 0.00736435\n",
      "Iteration 98, loss = 0.00735034\n",
      "Iteration 99, loss = 0.00833938\n",
      "Iteration 100, loss = 0.00741482\n",
      "Iteration 101, loss = 0.00730095\n",
      "Iteration 102, loss = 0.00729145\n",
      "Iteration 103, loss = 0.00728613\n",
      "Iteration 104, loss = 0.00707610\n",
      "Iteration 105, loss = 0.00710406\n",
      "Iteration 106, loss = 0.00723092\n",
      "Iteration 107, loss = 0.00732355\n",
      "Iteration 108, loss = 0.00711655\n",
      "Iteration 109, loss = 0.00835330\n",
      "Iteration 110, loss = 0.00715421\n",
      "Iteration 111, loss = 0.00702700\n",
      "Iteration 112, loss = 0.00712504\n",
      "Iteration 113, loss = 0.00735916\n",
      "Iteration 114, loss = 0.00713412\n",
      "Iteration 115, loss = 0.00881902\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.56508030\n",
      "Iteration 2, loss = 0.46536072\n",
      "Iteration 3, loss = 0.43110207\n",
      "Iteration 4, loss = 0.41754871\n",
      "Iteration 5, loss = 0.40865299\n",
      "Iteration 6, loss = 0.40097704\n",
      "Iteration 7, loss = 0.39392992\n",
      "Iteration 8, loss = 0.38666463\n",
      "Iteration 9, loss = 0.37938859\n",
      "Iteration 10, loss = 0.37131303\n",
      "Iteration 11, loss = 0.36299770\n",
      "Iteration 12, loss = 0.35397364\n",
      "Iteration 13, loss = 0.34476456\n",
      "Iteration 14, loss = 0.33527350\n",
      "Iteration 15, loss = 0.32474886\n",
      "Iteration 16, loss = 0.31431144\n",
      "Iteration 17, loss = 0.30325769\n",
      "Iteration 18, loss = 0.29200403\n",
      "Iteration 19, loss = 0.28004724\n",
      "Iteration 20, loss = 0.26812314\n",
      "Iteration 21, loss = 0.25538568\n",
      "Iteration 22, loss = 0.24317349\n",
      "Iteration 23, loss = 0.22986204\n",
      "Iteration 24, loss = 0.21641311\n",
      "Iteration 25, loss = 0.20306082\n",
      "Iteration 26, loss = 0.18952200\n",
      "Iteration 27, loss = 0.17641675\n",
      "Iteration 28, loss = 0.16318561\n",
      "Iteration 29, loss = 0.15074446\n",
      "Iteration 30, loss = 0.13864724\n",
      "Iteration 31, loss = 0.12637215\n",
      "Iteration 32, loss = 0.11549278\n",
      "Iteration 33, loss = 0.10495518\n",
      "Iteration 34, loss = 0.09493028\n",
      "Iteration 35, loss = 0.08610873\n",
      "Iteration 36, loss = 0.07841838\n",
      "Iteration 37, loss = 0.07067914\n",
      "Iteration 38, loss = 0.06389443\n",
      "Iteration 39, loss = 0.05784725\n",
      "Iteration 40, loss = 0.05230143\n",
      "Iteration 41, loss = 0.04746234\n",
      "Iteration 42, loss = 0.04315573\n",
      "Iteration 43, loss = 0.03945073\n",
      "Iteration 44, loss = 0.03583720\n",
      "Iteration 45, loss = 0.03292867\n",
      "Iteration 46, loss = 0.03021080\n",
      "Iteration 47, loss = 0.02785932\n",
      "Iteration 48, loss = 0.02578650\n",
      "Iteration 49, loss = 0.02383623\n",
      "Iteration 50, loss = 0.02215072\n",
      "Iteration 51, loss = 0.02061670\n",
      "Iteration 52, loss = 0.01942809\n",
      "Iteration 53, loss = 0.01814204\n",
      "Iteration 54, loss = 0.01719064\n",
      "Iteration 55, loss = 0.01615291\n",
      "Iteration 56, loss = 0.01539503\n",
      "Iteration 57, loss = 0.01456642\n",
      "Iteration 58, loss = 0.01391813\n",
      "Iteration 59, loss = 0.01324127\n",
      "Iteration 60, loss = 0.01292289\n",
      "Iteration 61, loss = 0.01243891\n",
      "Iteration 62, loss = 0.01161619\n",
      "Iteration 63, loss = 0.01111326\n",
      "Iteration 64, loss = 0.01076166\n",
      "Iteration 65, loss = 0.01050781\n",
      "Iteration 66, loss = 0.01016364\n",
      "Iteration 67, loss = 0.00984213\n",
      "Iteration 68, loss = 0.00950613\n",
      "Iteration 69, loss = 0.00918274\n",
      "Iteration 70, loss = 0.00898864\n",
      "Iteration 71, loss = 0.00881934\n",
      "Iteration 72, loss = 0.00871267\n",
      "Iteration 73, loss = 0.00843265\n",
      "Iteration 74, loss = 0.00830913\n",
      "Iteration 75, loss = 0.00816886\n",
      "Iteration 76, loss = 0.00803914\n",
      "Iteration 77, loss = 0.00788874\n",
      "Iteration 78, loss = 0.00784407\n",
      "Iteration 79, loss = 0.00759834\n",
      "Iteration 80, loss = 0.00839191\n",
      "Iteration 81, loss = 0.00748012\n",
      "Iteration 82, loss = 0.00738656\n",
      "Iteration 83, loss = 0.00742961\n",
      "Iteration 84, loss = 0.00736174\n",
      "Iteration 85, loss = 0.00734013\n",
      "Iteration 86, loss = 0.00726248\n",
      "Iteration 87, loss = 0.00726869\n",
      "Iteration 88, loss = 0.00714759\n",
      "Iteration 89, loss = 0.00702658\n",
      "Iteration 90, loss = 0.00712654\n",
      "Iteration 91, loss = 0.00721389\n",
      "Iteration 92, loss = 0.00705283\n",
      "Iteration 93, loss = 0.00703565\n",
      "Iteration 94, loss = 0.00690157\n",
      "Iteration 95, loss = 0.00687768\n",
      "Iteration 96, loss = 0.00681778\n",
      "Iteration 97, loss = 0.00685185\n",
      "Iteration 98, loss = 0.00677060\n",
      "Iteration 99, loss = 0.00668722\n",
      "Iteration 100, loss = 0.00678943\n",
      "Iteration 101, loss = 0.00683591\n",
      "Iteration 102, loss = 0.00675955\n",
      "Iteration 103, loss = 0.00678538\n",
      "Iteration 104, loss = 0.00664243\n",
      "Iteration 105, loss = 0.00696089\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.45113585\n",
      "Iteration 2, loss = 0.35351440\n",
      "Iteration 3, loss = 0.31723901\n",
      "Iteration 4, loss = 0.30063576\n",
      "Iteration 5, loss = 0.28870897\n",
      "Iteration 6, loss = 0.27827789\n",
      "Iteration 7, loss = 0.26854276\n",
      "Iteration 8, loss = 0.25843220\n",
      "Iteration 9, loss = 0.24852258\n",
      "Iteration 10, loss = 0.23789514\n",
      "Iteration 11, loss = 0.22703844\n",
      "Iteration 12, loss = 0.21624937\n",
      "Iteration 13, loss = 0.20532151\n",
      "Iteration 14, loss = 0.19401433\n",
      "Iteration 15, loss = 0.18301716\n",
      "Iteration 16, loss = 0.17178833\n",
      "Iteration 17, loss = 0.16068712\n",
      "Iteration 18, loss = 0.14877118\n",
      "Iteration 19, loss = 0.13771508\n",
      "Iteration 20, loss = 0.12686824\n",
      "Iteration 21, loss = 0.11616345\n",
      "Iteration 22, loss = 0.10573944\n",
      "Iteration 23, loss = 0.09574730\n",
      "Iteration 24, loss = 0.08658725\n",
      "Iteration 25, loss = 0.07772504\n",
      "Iteration 26, loss = 0.06985054\n",
      "Iteration 27, loss = 0.06229196\n",
      "Iteration 28, loss = 0.05531555\n",
      "Iteration 29, loss = 0.04935318\n",
      "Iteration 30, loss = 0.04399873\n",
      "Iteration 31, loss = 0.03902077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32, loss = 0.03485017\n",
      "Iteration 33, loss = 0.03139067\n",
      "Iteration 34, loss = 0.02790672\n",
      "Iteration 35, loss = 0.02504464\n",
      "Iteration 36, loss = 0.02250438\n",
      "Iteration 37, loss = 0.02041901\n",
      "Iteration 38, loss = 0.01858081\n",
      "Iteration 39, loss = 0.01695579\n",
      "Iteration 40, loss = 0.01542572\n",
      "Iteration 41, loss = 0.01416169\n",
      "Iteration 42, loss = 0.01309554\n",
      "Iteration 43, loss = 0.01206073\n",
      "Iteration 44, loss = 0.01117842\n",
      "Iteration 45, loss = 0.01045918\n",
      "Iteration 46, loss = 0.00981064\n",
      "Iteration 47, loss = 0.00920006\n",
      "Iteration 48, loss = 0.00871725\n",
      "Iteration 49, loss = 0.00833197\n",
      "Iteration 50, loss = 0.00782947\n",
      "Iteration 51, loss = 0.00751468\n",
      "Iteration 52, loss = 0.00715938\n",
      "Iteration 53, loss = 0.00690511\n",
      "Iteration 54, loss = 0.00672735\n",
      "Iteration 55, loss = 0.00647148\n",
      "Iteration 56, loss = 0.00630516\n",
      "Iteration 57, loss = 0.00612219\n",
      "Iteration 58, loss = 0.00592010\n",
      "Iteration 59, loss = 0.00578646\n",
      "Iteration 60, loss = 0.00567855\n",
      "Iteration 61, loss = 0.00564004\n",
      "Iteration 62, loss = 0.00547860\n",
      "Iteration 63, loss = 0.00537108\n",
      "Iteration 64, loss = 0.00530152\n",
      "Iteration 65, loss = 0.00519263\n",
      "Iteration 66, loss = 0.00513731\n",
      "Iteration 67, loss = 0.00512896\n",
      "Iteration 68, loss = 0.00507998\n",
      "Iteration 69, loss = 0.00504994\n",
      "Iteration 70, loss = 0.00500517\n",
      "Iteration 71, loss = 0.00485959\n",
      "Iteration 72, loss = 0.00480227\n",
      "Iteration 73, loss = 0.00485923\n",
      "Iteration 74, loss = 0.00477926\n",
      "Iteration 75, loss = 0.00466896\n",
      "Iteration 76, loss = 0.00474467\n",
      "Iteration 77, loss = 0.00458495\n",
      "Iteration 78, loss = 0.00456946\n",
      "Iteration 79, loss = 0.00460704\n",
      "Iteration 80, loss = 0.00451098\n",
      "Iteration 81, loss = 0.00461365\n",
      "Iteration 82, loss = 0.00453641\n",
      "Iteration 83, loss = 0.00437680\n",
      "Iteration 84, loss = 0.00437485\n",
      "Iteration 85, loss = 0.00439714\n",
      "Iteration 86, loss = 0.00437551\n",
      "Iteration 87, loss = 0.00430601\n",
      "Iteration 88, loss = 0.00420244\n",
      "Iteration 89, loss = 0.00427027\n",
      "Iteration 90, loss = 0.00428287\n",
      "Iteration 91, loss = 0.00421104\n",
      "Iteration 92, loss = 0.00413598\n",
      "Iteration 93, loss = 0.00416454\n",
      "Iteration 94, loss = 0.00400691\n",
      "Iteration 95, loss = 0.00404906\n",
      "Iteration 96, loss = 0.00388128\n",
      "Iteration 97, loss = 0.00391627\n",
      "Iteration 98, loss = 0.00385172\n",
      "Iteration 99, loss = 0.00387578\n",
      "Iteration 100, loss = 0.00384984\n",
      "Iteration 101, loss = 0.00380747\n",
      "Iteration 102, loss = 0.00385232\n",
      "Iteration 103, loss = 0.00383491\n",
      "Iteration 104, loss = 0.00371609\n",
      "Iteration 105, loss = 0.00368821\n",
      "Iteration 106, loss = 0.00368621\n",
      "Iteration 107, loss = 0.00374266\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.48661499\n",
      "Iteration 2, loss = 0.36012517\n",
      "Iteration 3, loss = 0.31422026\n",
      "Iteration 4, loss = 0.29119731\n",
      "Iteration 5, loss = 0.27743529\n",
      "Iteration 6, loss = 0.26541755\n",
      "Iteration 7, loss = 0.25275271\n",
      "Iteration 8, loss = 0.23927907\n",
      "Iteration 9, loss = 0.22476785\n",
      "Iteration 10, loss = 0.20979147\n",
      "Iteration 11, loss = 0.19478659\n",
      "Iteration 12, loss = 0.17972805\n",
      "Iteration 13, loss = 0.16496444\n",
      "Iteration 14, loss = 0.15083869\n",
      "Iteration 15, loss = 0.13757308\n",
      "Iteration 16, loss = 0.12491044\n",
      "Iteration 17, loss = 0.11329608\n",
      "Iteration 18, loss = 0.10235913\n",
      "Iteration 19, loss = 0.09234781\n",
      "Iteration 20, loss = 0.08317031\n",
      "Iteration 21, loss = 0.07451216\n",
      "Iteration 22, loss = 0.06681869\n",
      "Iteration 23, loss = 0.05983192\n",
      "Iteration 24, loss = 0.05358671\n",
      "Iteration 25, loss = 0.04792126\n",
      "Iteration 26, loss = 0.04277927\n",
      "Iteration 27, loss = 0.03841903\n",
      "Iteration 28, loss = 0.03433338\n",
      "Iteration 29, loss = 0.03074367\n",
      "Iteration 30, loss = 0.02769133\n",
      "Iteration 31, loss = 0.02492661\n",
      "Iteration 32, loss = 0.02250767\n",
      "Iteration 33, loss = 0.02043518\n",
      "Iteration 34, loss = 0.01860549\n",
      "Iteration 35, loss = 0.01696254\n",
      "Iteration 36, loss = 0.01560644\n",
      "Iteration 37, loss = 0.01436163\n",
      "Iteration 38, loss = 0.01331779\n",
      "Iteration 39, loss = 0.01235484\n",
      "Iteration 40, loss = 0.01150413\n",
      "Iteration 41, loss = 0.01072618\n",
      "Iteration 42, loss = 0.01010988\n",
      "Iteration 43, loss = 0.00953161\n",
      "Iteration 44, loss = 0.00907659\n",
      "Iteration 45, loss = 0.00858970\n",
      "Iteration 46, loss = 0.00824875\n",
      "Iteration 47, loss = 0.00782756\n",
      "Iteration 48, loss = 0.00749974\n",
      "Iteration 49, loss = 0.00723585\n",
      "Iteration 50, loss = 0.00697978\n",
      "Iteration 51, loss = 0.00672092\n",
      "Iteration 52, loss = 0.00654232\n",
      "Iteration 53, loss = 0.00632571\n",
      "Iteration 54, loss = 0.00618353\n",
      "Iteration 55, loss = 0.00602732\n",
      "Iteration 56, loss = 0.00589037\n",
      "Iteration 57, loss = 0.00577074\n",
      "Iteration 58, loss = 0.00564426\n",
      "Iteration 59, loss = 0.00549052\n",
      "Iteration 60, loss = 0.00539800\n",
      "Iteration 61, loss = 0.00533105\n",
      "Iteration 62, loss = 0.00519700\n",
      "Iteration 63, loss = 0.00512134\n",
      "Iteration 64, loss = 0.00503018\n",
      "Iteration 65, loss = 0.00496233\n",
      "Iteration 66, loss = 0.00488050\n",
      "Iteration 67, loss = 0.00481972\n",
      "Iteration 68, loss = 0.00469358\n",
      "Iteration 69, loss = 0.00461561\n",
      "Iteration 70, loss = 0.00459260\n",
      "Iteration 71, loss = 0.00458198\n",
      "Iteration 72, loss = 0.00443821\n",
      "Iteration 73, loss = 0.00439855\n",
      "Iteration 74, loss = 0.00433311\n",
      "Iteration 75, loss = 0.00427965\n",
      "Iteration 76, loss = 0.00425190\n",
      "Iteration 77, loss = 0.00416178\n",
      "Iteration 78, loss = 0.00415575\n",
      "Iteration 79, loss = 0.00406768\n",
      "Iteration 80, loss = 0.00405143\n",
      "Iteration 81, loss = 0.00403230\n",
      "Iteration 82, loss = 0.00401912\n",
      "Iteration 83, loss = 0.00392275\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.44313319\n",
      "Iteration 2, loss = 0.31063903\n",
      "Iteration 3, loss = 0.26585621\n",
      "Iteration 4, loss = 0.24752892\n",
      "Iteration 5, loss = 0.23621348\n",
      "Iteration 6, loss = 0.22694952\n",
      "Iteration 7, loss = 0.21856111\n",
      "Iteration 8, loss = 0.21068604\n",
      "Iteration 9, loss = 0.20262205\n",
      "Iteration 10, loss = 0.19446998\n",
      "Iteration 11, loss = 0.18614590\n",
      "Iteration 12, loss = 0.17768416\n",
      "Iteration 13, loss = 0.16902993\n",
      "Iteration 14, loss = 0.16036909\n",
      "Iteration 15, loss = 0.15187724\n",
      "Iteration 16, loss = 0.14334168\n",
      "Iteration 17, loss = 0.13447360\n",
      "Iteration 18, loss = 0.12577254\n",
      "Iteration 19, loss = 0.11747093\n",
      "Iteration 20, loss = 0.10929793\n",
      "Iteration 21, loss = 0.10097473\n",
      "Iteration 22, loss = 0.09313397\n",
      "Iteration 23, loss = 0.08572105\n",
      "Iteration 24, loss = 0.07843831\n",
      "Iteration 25, loss = 0.07175578\n",
      "Iteration 26, loss = 0.06524002\n",
      "Iteration 27, loss = 0.05927654\n",
      "Iteration 28, loss = 0.05379457\n",
      "Iteration 29, loss = 0.04887059\n",
      "Iteration 30, loss = 0.04396187\n",
      "Iteration 31, loss = 0.03984379\n",
      "Iteration 32, loss = 0.03599475\n",
      "Iteration 33, loss = 0.03260591\n",
      "Iteration 34, loss = 0.02948104\n",
      "Iteration 35, loss = 0.02673644\n",
      "Iteration 36, loss = 0.02433296\n",
      "Iteration 37, loss = 0.02222729\n",
      "Iteration 38, loss = 0.02023999\n",
      "Iteration 39, loss = 0.01858047\n",
      "Iteration 40, loss = 0.01695580\n",
      "Iteration 41, loss = 0.01568376\n",
      "Iteration 42, loss = 0.01450729\n",
      "Iteration 43, loss = 0.01333744\n",
      "Iteration 44, loss = 0.01241132\n",
      "Iteration 45, loss = 0.01169551\n",
      "Iteration 46, loss = 0.01088350\n",
      "Iteration 47, loss = 0.01022026\n",
      "Iteration 48, loss = 0.00970427\n",
      "Iteration 49, loss = 0.00916905\n",
      "Iteration 50, loss = 0.00868066\n",
      "Iteration 51, loss = 0.00823168\n",
      "Iteration 52, loss = 0.00788970\n",
      "Iteration 53, loss = 0.00755184\n",
      "Iteration 54, loss = 0.00723801\n",
      "Iteration 55, loss = 0.00702508\n",
      "Iteration 56, loss = 0.00680069\n",
      "Iteration 57, loss = 0.00657496\n",
      "Iteration 58, loss = 0.00640853\n",
      "Iteration 59, loss = 0.00619463\n",
      "Iteration 60, loss = 0.00604674\n",
      "Iteration 61, loss = 0.00583513\n",
      "Iteration 62, loss = 0.00573290\n",
      "Iteration 63, loss = 0.00562647\n",
      "Iteration 64, loss = 0.00549570\n",
      "Iteration 65, loss = 0.00539511\n",
      "Iteration 66, loss = 0.00530989\n",
      "Iteration 67, loss = 0.00520445\n",
      "Iteration 68, loss = 0.00526639\n",
      "Iteration 69, loss = 0.00514415\n",
      "Iteration 70, loss = 0.00501454\n",
      "Iteration 71, loss = 0.00488351\n",
      "Iteration 72, loss = 0.00480638\n",
      "Iteration 73, loss = 0.00474928\n",
      "Iteration 74, loss = 0.00466071\n",
      "Iteration 75, loss = 0.00460815\n",
      "Iteration 76, loss = 0.00453958\n",
      "Iteration 77, loss = 0.00450747\n",
      "Iteration 78, loss = 0.00441288\n",
      "Iteration 79, loss = 0.00436858\n",
      "Iteration 80, loss = 0.00429205\n",
      "Iteration 81, loss = 0.00425215\n",
      "Iteration 82, loss = 0.00424912\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.38617404\n",
      "Iteration 2, loss = 0.23280511\n",
      "Iteration 3, loss = 0.18127135\n",
      "Iteration 4, loss = 0.15815393\n",
      "Iteration 5, loss = 0.14621796\n",
      "Iteration 6, loss = 0.13760592\n",
      "Iteration 7, loss = 0.13073539\n",
      "Iteration 8, loss = 0.12465843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.11910592\n",
      "Iteration 10, loss = 0.11385689\n",
      "Iteration 11, loss = 0.10872303\n",
      "Iteration 12, loss = 0.10403362\n",
      "Iteration 13, loss = 0.09887034\n",
      "Iteration 14, loss = 0.09399495\n",
      "Iteration 15, loss = 0.08940384\n",
      "Iteration 16, loss = 0.08462770\n",
      "Iteration 17, loss = 0.08009332\n",
      "Iteration 18, loss = 0.07548959\n",
      "Iteration 19, loss = 0.07104561\n",
      "Iteration 20, loss = 0.06649942\n",
      "Iteration 21, loss = 0.06202382\n",
      "Iteration 22, loss = 0.05770934\n",
      "Iteration 23, loss = 0.05360682\n",
      "Iteration 24, loss = 0.04945231\n",
      "Iteration 25, loss = 0.04578131\n",
      "Iteration 26, loss = 0.04190559\n",
      "Iteration 27, loss = 0.03842857\n",
      "Iteration 28, loss = 0.03569990\n",
      "Iteration 29, loss = 0.03232472\n",
      "Iteration 30, loss = 0.02965213\n",
      "Iteration 31, loss = 0.02720536\n",
      "Iteration 32, loss = 0.02457382\n",
      "Iteration 33, loss = 0.02257413\n",
      "Iteration 34, loss = 0.02053614\n",
      "Iteration 35, loss = 0.01885014\n",
      "Iteration 36, loss = 0.01709383\n",
      "Iteration 37, loss = 0.01564236\n",
      "Iteration 38, loss = 0.01458740\n",
      "Iteration 39, loss = 0.01327675\n",
      "Iteration 40, loss = 0.01225357\n",
      "Iteration 41, loss = 0.01126518\n",
      "Iteration 42, loss = 0.01043551\n",
      "Iteration 43, loss = 0.00991572\n",
      "Iteration 44, loss = 0.00916474\n",
      "Iteration 45, loss = 0.00848929\n",
      "Iteration 46, loss = 0.00791956\n",
      "Iteration 47, loss = 0.00751139\n",
      "Iteration 48, loss = 0.00701635\n",
      "Iteration 49, loss = 0.00666411\n",
      "Iteration 50, loss = 0.00630692\n",
      "Iteration 51, loss = 0.00600716\n",
      "Iteration 52, loss = 0.00574972\n",
      "Iteration 53, loss = 0.00549399\n",
      "Iteration 54, loss = 0.00525841\n",
      "Iteration 55, loss = 0.00505465\n",
      "Iteration 56, loss = 0.00489382\n",
      "Iteration 57, loss = 0.00472329\n",
      "Iteration 58, loss = 0.00459181\n",
      "Iteration 59, loss = 0.00446495\n",
      "Iteration 60, loss = 0.00431010\n",
      "Iteration 61, loss = 0.00424840\n",
      "Iteration 62, loss = 0.00408729\n",
      "Iteration 63, loss = 0.00403646\n",
      "Iteration 64, loss = 0.00396529\n",
      "Iteration 65, loss = 0.00386976\n",
      "Iteration 66, loss = 0.00377212\n",
      "Iteration 67, loss = 0.00368660\n",
      "Iteration 68, loss = 0.00366963\n",
      "Iteration 69, loss = 0.00362267\n",
      "Iteration 70, loss = 0.00354412\n",
      "Iteration 71, loss = 0.00353256\n",
      "Iteration 72, loss = 0.00346462\n",
      "Iteration 73, loss = 0.00338997\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.42757650\n",
      "Iteration 2, loss = 0.26467720\n",
      "Iteration 3, loss = 0.22975710\n",
      "Iteration 4, loss = 0.20754405\n",
      "Iteration 5, loss = 0.19385628\n",
      "Iteration 6, loss = 0.18254787\n",
      "Iteration 7, loss = 0.17203799\n",
      "Iteration 8, loss = 0.16125759\n",
      "Iteration 9, loss = 0.15077411\n",
      "Iteration 10, loss = 0.14022128\n",
      "Iteration 11, loss = 0.12983308\n",
      "Iteration 12, loss = 0.11985111\n",
      "Iteration 13, loss = 0.10983763\n",
      "Iteration 14, loss = 0.10022155\n",
      "Iteration 15, loss = 0.09109602\n",
      "Iteration 16, loss = 0.08229121\n",
      "Iteration 17, loss = 0.07411531\n",
      "Iteration 18, loss = 0.06640833\n",
      "Iteration 19, loss = 0.05949140\n",
      "Iteration 20, loss = 0.05293750\n",
      "Iteration 21, loss = 0.04726489\n",
      "Iteration 22, loss = 0.04193956\n",
      "Iteration 23, loss = 0.03718076\n",
      "Iteration 24, loss = 0.03292950\n",
      "Iteration 25, loss = 0.02924512\n",
      "Iteration 26, loss = 0.02606198\n",
      "Iteration 27, loss = 0.02316797\n",
      "Iteration 28, loss = 0.02074120\n",
      "Iteration 29, loss = 0.01850919\n",
      "Iteration 30, loss = 0.01667388\n",
      "Iteration 31, loss = 0.01496669\n",
      "Iteration 32, loss = 0.01358056\n",
      "Iteration 33, loss = 0.01232045\n",
      "Iteration 34, loss = 0.01128387\n",
      "Iteration 35, loss = 0.01038806\n",
      "Iteration 36, loss = 0.00955368\n",
      "Iteration 37, loss = 0.00889907\n",
      "Iteration 38, loss = 0.00831007\n",
      "Iteration 39, loss = 0.00772226\n",
      "Iteration 40, loss = 0.00724314\n",
      "Iteration 41, loss = 0.00683109\n",
      "Iteration 42, loss = 0.00646367\n",
      "Iteration 43, loss = 0.00614636\n",
      "Iteration 44, loss = 0.00584873\n",
      "Iteration 45, loss = 0.00559809\n",
      "Iteration 46, loss = 0.00537982\n",
      "Iteration 47, loss = 0.00517792\n",
      "Iteration 48, loss = 0.00499974\n",
      "Iteration 49, loss = 0.00483929\n",
      "Iteration 50, loss = 0.00468859\n",
      "Iteration 51, loss = 0.00456391\n",
      "Iteration 52, loss = 0.00444604\n",
      "Iteration 53, loss = 0.00433220\n",
      "Iteration 54, loss = 0.00422647\n",
      "Iteration 55, loss = 0.00413143\n",
      "Iteration 56, loss = 0.00403911\n",
      "Iteration 57, loss = 0.00397023\n",
      "Iteration 58, loss = 0.00387753\n",
      "Iteration 59, loss = 0.00381854\n",
      "Iteration 60, loss = 0.00375154\n",
      "Iteration 61, loss = 0.00368408\n",
      "Iteration 62, loss = 0.00362705\n",
      "Iteration 63, loss = 0.00356434\n",
      "Iteration 64, loss = 0.00349989\n",
      "Iteration 65, loss = 0.00344639\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.30859279\n",
      "Iteration 2, loss = 0.16672328\n",
      "Iteration 3, loss = 0.12506247\n",
      "Iteration 4, loss = 0.10887746\n",
      "Iteration 5, loss = 0.09891719\n",
      "Iteration 6, loss = 0.09125631\n",
      "Iteration 7, loss = 0.08478466\n",
      "Iteration 8, loss = 0.07888129\n",
      "Iteration 9, loss = 0.07326027\n",
      "Iteration 10, loss = 0.06839933\n",
      "Iteration 11, loss = 0.06365951\n",
      "Iteration 12, loss = 0.05903708\n",
      "Iteration 13, loss = 0.05489314\n",
      "Iteration 14, loss = 0.05087385\n",
      "Iteration 15, loss = 0.04690919\n",
      "Iteration 16, loss = 0.04328515\n",
      "Iteration 17, loss = 0.03975797\n",
      "Iteration 18, loss = 0.03634970\n",
      "Iteration 19, loss = 0.03309085\n",
      "Iteration 20, loss = 0.03046453\n",
      "Iteration 21, loss = 0.02751719\n",
      "Iteration 22, loss = 0.02496094\n",
      "Iteration 23, loss = 0.02271771\n",
      "Iteration 24, loss = 0.02040444\n",
      "Iteration 25, loss = 0.01841739\n",
      "Iteration 26, loss = 0.01663773\n",
      "Iteration 27, loss = 0.01506474\n",
      "Iteration 28, loss = 0.01369709\n",
      "Iteration 29, loss = 0.01236775\n",
      "Iteration 30, loss = 0.01126667\n",
      "Iteration 31, loss = 0.01034054\n",
      "Iteration 32, loss = 0.00952917\n",
      "Iteration 33, loss = 0.00868200\n",
      "Iteration 34, loss = 0.00801716\n",
      "Iteration 35, loss = 0.00743752\n",
      "Iteration 36, loss = 0.00686123\n",
      "Iteration 37, loss = 0.00638889\n",
      "Iteration 38, loss = 0.00601443\n",
      "Iteration 39, loss = 0.00565609\n",
      "Iteration 40, loss = 0.00532190\n",
      "Iteration 41, loss = 0.00512542\n",
      "Iteration 42, loss = 0.00478414\n",
      "Iteration 43, loss = 0.00456415\n",
      "Iteration 44, loss = 0.00434322\n",
      "Iteration 45, loss = 0.00417036\n",
      "Iteration 46, loss = 0.00399368\n",
      "Iteration 47, loss = 0.00384996\n",
      "Iteration 48, loss = 0.00374024\n",
      "Iteration 49, loss = 0.00360877\n",
      "Iteration 50, loss = 0.00350633\n",
      "Iteration 51, loss = 0.00345890\n",
      "Iteration 52, loss = 0.00333487\n",
      "Iteration 53, loss = 0.00324478\n",
      "Iteration 54, loss = 0.00319588\n",
      "Iteration 55, loss = 0.00312220\n",
      "Iteration 56, loss = 0.00303716\n",
      "Iteration 57, loss = 0.00295730\n",
      "Iteration 58, loss = 0.00295548\n",
      "Iteration 59, loss = 0.00290501\n",
      "Iteration 60, loss = 0.00284239\n",
      "Iteration 61, loss = 0.00277862\n",
      "Iteration 62, loss = 0.00276081\n",
      "Iteration 63, loss = 0.00273613\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.36096335\n",
      "Iteration 2, loss = 0.23591766\n",
      "Iteration 3, loss = 0.20963951\n",
      "Iteration 4, loss = 0.19050834\n",
      "Iteration 5, loss = 0.17756059\n",
      "Iteration 6, loss = 0.16692462\n",
      "Iteration 7, loss = 0.15726766\n",
      "Iteration 8, loss = 0.14756078\n",
      "Iteration 9, loss = 0.13767336\n",
      "Iteration 10, loss = 0.12810773\n",
      "Iteration 11, loss = 0.11816246\n",
      "Iteration 12, loss = 0.10844750\n",
      "Iteration 13, loss = 0.09913008\n",
      "Iteration 14, loss = 0.09022239\n",
      "Iteration 15, loss = 0.08180923\n",
      "Iteration 16, loss = 0.07410432\n",
      "Iteration 17, loss = 0.06680097\n",
      "Iteration 18, loss = 0.06019633\n",
      "Iteration 19, loss = 0.05403241\n",
      "Iteration 20, loss = 0.04851523\n",
      "Iteration 21, loss = 0.04344634\n",
      "Iteration 22, loss = 0.03889704\n",
      "Iteration 23, loss = 0.03484017\n",
      "Iteration 24, loss = 0.03106317\n",
      "Iteration 25, loss = 0.02780117\n",
      "Iteration 26, loss = 0.02495765\n",
      "Iteration 27, loss = 0.02230598\n",
      "Iteration 28, loss = 0.01991131\n",
      "Iteration 29, loss = 0.01787564\n",
      "Iteration 30, loss = 0.01602898\n",
      "Iteration 31, loss = 0.01448297\n",
      "Iteration 32, loss = 0.01307367\n",
      "Iteration 33, loss = 0.01185222\n",
      "Iteration 34, loss = 0.01082101\n",
      "Iteration 35, loss = 0.00993330\n",
      "Iteration 36, loss = 0.00909077\n",
      "Iteration 37, loss = 0.00838793\n",
      "Iteration 38, loss = 0.00778434\n",
      "Iteration 39, loss = 0.00725951\n",
      "Iteration 40, loss = 0.00677628\n",
      "Iteration 41, loss = 0.00635843\n",
      "Iteration 42, loss = 0.00598755\n",
      "Iteration 43, loss = 0.00568443\n",
      "Iteration 44, loss = 0.00539761\n",
      "Iteration 45, loss = 0.00514078\n",
      "Iteration 46, loss = 0.00491276\n",
      "Iteration 47, loss = 0.00473018\n",
      "Iteration 48, loss = 0.00455134\n",
      "Iteration 49, loss = 0.00437910\n",
      "Iteration 50, loss = 0.00423296\n",
      "Iteration 51, loss = 0.00409541\n",
      "Iteration 52, loss = 0.00399572\n",
      "Iteration 53, loss = 0.00386492\n",
      "Iteration 54, loss = 0.00378611\n",
      "Iteration 55, loss = 0.00368461\n",
      "Iteration 56, loss = 0.00359718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 57, loss = 0.00351049\n",
      "Iteration 58, loss = 0.00345532\n",
      "Iteration 59, loss = 0.00336259\n",
      "Iteration 60, loss = 0.00330289\n",
      "Iteration 61, loss = 0.00327556\n",
      "Iteration 62, loss = 0.00316574\n",
      "Iteration 63, loss = 0.00311354\n",
      "Iteration 64, loss = 0.00308787\n",
      "Iteration 65, loss = 0.00301420\n",
      "Iteration 66, loss = 0.00297980\n",
      "Iteration 67, loss = 0.00294497\n",
      "Iteration 68, loss = 0.00289236\n",
      "Iteration 69, loss = 0.00287244\n",
      "Iteration 70, loss = 0.00282110\n",
      "Iteration 71, loss = 0.00276974\n",
      "Iteration 72, loss = 0.00268753\n",
      "Iteration 73, loss = 0.00269484\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 0.34887363\n",
      "Iteration 2, loss = 0.18740994\n",
      "Iteration 3, loss = 0.14263801\n",
      "Iteration 4, loss = 0.12278086\n",
      "Iteration 5, loss = 0.11090925\n",
      "Iteration 6, loss = 0.10199229\n",
      "Iteration 7, loss = 0.09428112\n",
      "Iteration 8, loss = 0.08733229\n",
      "Iteration 9, loss = 0.08089692\n",
      "Iteration 10, loss = 0.07468835\n",
      "Iteration 11, loss = 0.06858331\n",
      "Iteration 12, loss = 0.06290512\n",
      "Iteration 13, loss = 0.05747880\n",
      "Iteration 14, loss = 0.05232645\n",
      "Iteration 15, loss = 0.04750315\n",
      "Iteration 16, loss = 0.04295485\n",
      "Iteration 17, loss = 0.03875983\n",
      "Iteration 18, loss = 0.03485803\n",
      "Iteration 19, loss = 0.03136373\n",
      "Iteration 20, loss = 0.02798802\n",
      "Iteration 21, loss = 0.02499853\n",
      "Iteration 22, loss = 0.02233464\n",
      "Iteration 23, loss = 0.01992251\n",
      "Iteration 24, loss = 0.01773936\n",
      "Iteration 25, loss = 0.01590669\n",
      "Iteration 26, loss = 0.01419667\n",
      "Iteration 27, loss = 0.01275965\n",
      "Iteration 28, loss = 0.01146811\n",
      "Iteration 29, loss = 0.01044224\n",
      "Iteration 30, loss = 0.00943262\n",
      "Iteration 31, loss = 0.00859044\n",
      "Iteration 32, loss = 0.00786745\n",
      "Iteration 33, loss = 0.00726404\n",
      "Iteration 34, loss = 0.00670995\n",
      "Iteration 35, loss = 0.00622872\n",
      "Iteration 36, loss = 0.00582555\n",
      "Iteration 37, loss = 0.00546205\n",
      "Iteration 38, loss = 0.00513441\n",
      "Iteration 39, loss = 0.00486815\n",
      "Iteration 40, loss = 0.00461356\n",
      "Iteration 41, loss = 0.00439602\n",
      "Iteration 42, loss = 0.00419467\n",
      "Iteration 43, loss = 0.00402345\n",
      "Iteration 44, loss = 0.00387229\n",
      "Iteration 45, loss = 0.00372787\n",
      "Iteration 46, loss = 0.00361894\n",
      "Iteration 47, loss = 0.00349723\n",
      "Iteration 48, loss = 0.00339128\n",
      "Iteration 49, loss = 0.00331319\n",
      "Iteration 50, loss = 0.00321370\n",
      "Iteration 51, loss = 0.00313434\n",
      "Iteration 52, loss = 0.00306044\n",
      "Iteration 53, loss = 0.00300097\n",
      "Iteration 54, loss = 0.00293351\n",
      "Iteration 55, loss = 0.00287848\n",
      "Iteration 56, loss = 0.00281302\n",
      "Iteration 57, loss = 0.00278759\n",
      "Iteration 58, loss = 0.00272324\n",
      "Iteration 59, loss = 0.00267335\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "[[[6.44996815e-03 9.93550032e-01]\n",
      "  [9.99187561e-01 8.12438970e-04]\n",
      "  [9.08918497e-01 9.10815033e-02]\n",
      "  ...\n",
      "  [9.92675571e-01 7.32442918e-03]\n",
      "  [9.99112581e-01 8.87419402e-04]\n",
      "  [9.79034394e-01 2.09656056e-02]]\n",
      "\n",
      " [[9.99954878e-01 4.51224789e-05]\n",
      "  [9.38616114e-01 6.13838860e-02]\n",
      "  [9.99627885e-01 3.72114952e-04]\n",
      "  ...\n",
      "  [9.99981008e-01 1.89921696e-05]\n",
      "  [9.98808158e-01 1.19184220e-03]\n",
      "  [9.99461379e-01 5.38620783e-04]]\n",
      "\n",
      " [[9.86591231e-01 1.34087695e-02]\n",
      "  [1.00000000e+00 1.30701981e-10]\n",
      "  [9.99837910e-01 1.62090107e-04]\n",
      "  ...\n",
      "  [9.99993178e-01 6.82224783e-06]\n",
      "  [9.99999998e-01 1.69695951e-09]\n",
      "  [9.71811434e-01 2.81885657e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2.79310844e-01 7.20689156e-01]\n",
      "  [1.32262741e-01 8.67737259e-01]\n",
      "  [9.99994383e-01 5.61706237e-06]\n",
      "  ...\n",
      "  [9.66034332e-01 3.39656679e-02]\n",
      "  [4.03938486e-02 9.59606151e-01]\n",
      "  [9.99999997e-01 2.85292293e-09]]\n",
      "\n",
      " [[9.99999985e-01 1.51603597e-08]\n",
      "  [9.99996345e-01 3.65526518e-06]\n",
      "  [1.00000000e+00 4.66213455e-11]\n",
      "  ...\n",
      "  [9.98439511e-01 1.56048854e-03]\n",
      "  [9.99999985e-01 1.52690420e-08]\n",
      "  [9.99902859e-01 9.71412955e-05]]\n",
      "\n",
      " [[9.99999821e-01 1.78889684e-07]\n",
      "  [9.99999863e-01 1.36806989e-07]\n",
      "  [9.99998298e-01 1.70179707e-06]\n",
      "  ...\n",
      "  [9.99999807e-01 1.93099533e-07]\n",
      "  [9.99999406e-01 5.93911190e-07]\n",
      "  [4.45471660e-10 1.00000000e+00]]]\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Drama       0.63      0.64      0.63      3975\n",
      "         Comedy       0.55      0.52      0.53      2573\n",
      "       Thriller       0.45      0.38      0.41      1505\n",
      "        Romance       0.44      0.32      0.37      1352\n",
      "         Action       0.50      0.41      0.45      1347\n",
      "         Horror       0.56      0.50      0.53       941\n",
      "          Crime       0.43      0.30      0.35       837\n",
      "    Documentary       0.60      0.61      0.60       740\n",
      "      Adventure       0.41      0.25      0.31       726\n",
      "Science Fiction       0.55      0.44      0.49       619\n",
      "\n",
      "      micro avg       0.55      0.48      0.51     14615\n",
      "      macro avg       0.51      0.44      0.47     14615\n",
      "   weighted avg       0.54      0.48      0.51     14615\n",
      "    samples avg       0.63      0.57      0.64     14615\n",
      "\n",
      "\n",
      "Hamming Loss:\n",
      "0.15083679658542065\n",
      "\n",
      "F1 Score:\n",
      "0.5122225854491301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model3 = MultiOutputClassifier(MLPClassifier(hidden_layer_sizes=(50,), verbose = True, max_iter=200))\n",
    "model3.fit(X_train, y_train)\n",
    "# Dự đoán nhãn\n",
    "y_pred_proba3 = model3.predict_proba(X_test)\n",
    "\n",
    "# Chuyển đổi xác suất thành nhãn dự đoán\n",
    "y_pred3 = np.zeros_like(y_test)\n",
    "\n",
    "# y_pred_proba1 là một danh sách của các mảng xác suất cho từng nhãn\n",
    "# Chuyển đổi y_pred_proba1 sang định dạng numpy để dễ thao tác hơn\n",
    "y_pred_proba3 = np.array(y_pred_proba3)\n",
    "print(y_pred_proba3)\n",
    "# Lấy số lượng nhãn từ num_labels_test\n",
    "for i in range(len(y_test)):\n",
    "    # Lấy xác suất dự đoán cho mẫu thứ i\n",
    "    proba3 = np.array([y_pred_proba3[j][:, 1][i] for j in range(len(y_pred_proba3))])\n",
    "    top_k_indices3 = np.where(proba3 > 0.5)[0]\n",
    "    if len(top_k_indices3) == 0:\n",
    "        y_pred3[i, top_k_indices3] = 0\n",
    "    else:\n",
    "        y_pred3[i, top_k_indices3] = 1\n",
    "\n",
    "# Đánh giá mô hình\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred3, target_names=genre_counts, zero_division=1))\n",
    "\n",
    "print(\"\\nHamming Loss:\")\n",
    "print(hamming_loss(y_test, y_pred3))\n",
    "\n",
    "print(\"\\nF1 Score:\")\n",
    "print(f1_score(y_test, y_pred3, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34fa1fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báo cáo phân loại:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Drama       0.67      0.54      0.60      3975\n",
      "         Comedy       0.78      0.22      0.35      2573\n",
      "       Thriller       0.62      0.15      0.24      1505\n",
      "        Romance       0.63      0.20      0.30      1352\n",
      "         Action       0.71      0.22      0.33      1347\n",
      "         Horror       0.76      0.27      0.39       941\n",
      "          Crime       0.54      0.18      0.27       837\n",
      "    Documentary       0.76      0.47      0.58       740\n",
      "      Adventure       0.51      0.08      0.14       726\n",
      "Science Fiction       0.75      0.35      0.48       619\n",
      "\n",
      "      micro avg       0.69      0.31      0.43     14615\n",
      "      macro avg       0.67      0.27      0.37     14615\n",
      "   weighted avg       0.68      0.31      0.40     14615\n",
      "    samples avg       0.82      0.41      0.50     14615\n",
      "\n",
      "\n",
      "Hamming Loss:\n",
      "0.1366168707177356\n",
      "\n",
      "F1 Score:\n",
      "0.42700334479672114\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import classification_report, hamming_loss, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "model = MultiOutputClassifier(GradientBoostingClassifier(n_estimators=400, random_state=42))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán xác suất\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "# Chuyển đổi xác suất thành nhãn dự đoán\n",
    "y_pred = np.zeros_like(y_test)\n",
    "\n",
    "# y_pred_proba là một danh sách của các mảng xác suất cho từng nhãn\n",
    "# Chuyển đổi y_pred_proba sang định dạng numpy để dễ thao tác hơn\n",
    "y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "# Lấy số lượng nhãn từ num_labels_test\n",
    "for i in range(len(y_test)):\n",
    "    # Lấy xác suất dự đoán cho mẫu thứ i\n",
    "    proba4 = np.array([y_pred_proba[j][:, 1][i] for j in range(len(y_pred_proba))])\n",
    "    \n",
    "    top_k_indices4 = np.where(proba4 > 0.5)[0]\n",
    "    if len(top_k_indices4) == 0:\n",
    "        y_pred[i, top_k_indices4] = 0\n",
    "    else:\n",
    "        y_pred[i, top_k_indices4] = 1\n",
    "\n",
    "# Đánh giá mô hình\n",
    "print(\"Báo cáo phân loại:\")\n",
    "print(classification_report(y_test, y_pred, target_names=genre_counts, zero_division=1))\n",
    "\n",
    "print(\"\\nHamming Loss:\")\n",
    "print(hamming_loss(y_test, y_pred))\n",
    "\n",
    "print(\"\\nF1 Score:\")\n",
    "print(f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2a1d15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Báo cáo phân loại:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Drama       0.68      0.64      0.66      3975\n",
      "         Comedy       0.70      0.39      0.50      2573\n",
      "       Thriller       0.61      0.22      0.33      1505\n",
      "        Romance       0.63      0.22      0.33      1352\n",
      "         Action       0.70      0.29      0.41      1347\n",
      "         Horror       0.79      0.30      0.44       941\n",
      "          Crime       0.60      0.19      0.29       837\n",
      "    Documentary       0.80      0.46      0.58       740\n",
      "      Adventure       0.68      0.11      0.19       726\n",
      "Science Fiction       0.84      0.32      0.47       619\n",
      "\n",
      "      micro avg       0.69      0.39      0.49     14615\n",
      "      macro avg       0.70      0.31      0.42     14615\n",
      "   weighted avg       0.69      0.39      0.47     14615\n",
      "    samples avg       0.79      0.49      0.58     14615\n",
      "\n",
      "\n",
      "Hamming Loss:\n",
      "0.1294619791081658\n",
      "\n",
      "F1 Score:\n",
      "0.4940298507462687\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, hamming_loss, f1_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "\n",
    "model5 = MultiOutputClassifier(LogisticRegression(max_iter=400))\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán xác suất\n",
    "y_pred_proba5 = model5.predict_proba(X_test)\n",
    "\n",
    "# Chuyển đổi xác suất thành nhãn dự đoán\n",
    "y_pred5 = np.zeros_like(y_test)\n",
    "\n",
    "# y_pred_proba1 là một danh sách của các mảng xác suất cho từng nhãn\n",
    "# Chuyển đổi y_pred_proba1 sang định dạng numpy để dễ thao tác hơn\n",
    "y_pred_proba5 = np.array(y_pred_proba5)\n",
    "\n",
    "# Lấy số lượng nhãn từ num_labels_test\n",
    "for i in range(len(y_test)):\n",
    "    # Lấy xác suất dự đoán cho mẫu thứ i\n",
    "    proba5 = np.array([y_pred_proba5[j][:, 1][i] for j in range(len(y_pred_proba5))])\n",
    "    top_k_indices5 = np.where(proba5 > 0.5)[0]\n",
    "    if len(top_k_indices5) == 0:\n",
    "        y_pred5[i, top_k_indices5] = 0\n",
    "    else:\n",
    "        y_pred5[i, top_k_indices5] = 1\n",
    "\n",
    "# Đánh giá mô hình\n",
    "print(\"Báo cáo phân loại:\")\n",
    "print(classification_report(y_test, y_pred5, target_names=genre_counts, zero_division=1))\n",
    "\n",
    "print(\"\\nHamming Loss:\")\n",
    "print(hamming_loss(y_test, y_pred5))\n",
    "\n",
    "print(\"\\nF1 Score:\")\n",
    "print(f1_score(y_test, y_pred5, average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39da6b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "categories = ['random forest', 'mlp classifier', 'gb classifier', 'logistic regression']\n",
    "values = [hamming_loss(y_test, y_pred1),  hamming_loss(y_test, y_pred3), hamming_loss(y_test, y_pred), hamming_loss(y_test, y_pred5)]\n",
    "\n",
    "plt.bar(categories, values, color='skyblue')\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Hamming Loss:')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4f91f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Drama'],\n",
       " ['Drama'],\n",
       " [],\n",
       " ['Drama', 'Action'],\n",
       " ['Drama'],\n",
       " ['Drama', 'Action'],\n",
       " ['Comedy'],\n",
       " [],\n",
       " ['Comedy'],\n",
       " []]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds1 = final_genres.inverse_transform(y_pred1)\n",
    "[list(i) for i in test_preds1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f03d6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Drama', 'Documentary'],\n",
       " ['Documentary'],\n",
       " [],\n",
       " ['Action'],\n",
       " ['Drama', 'Comedy'],\n",
       " ['Drama', 'Action'],\n",
       " ['Comedy'],\n",
       " [],\n",
       " ['Comedy'],\n",
       " ['Action', 'Crime']]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds3 = final_genres.inverse_transform(y_pred3)\n",
    "[list(i) for i in test_preds3][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad2f5023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Drama'],\n",
       " ['Drama'],\n",
       " [],\n",
       " [],\n",
       " ['Drama'],\n",
       " ['Drama', 'Action'],\n",
       " ['Comedy'],\n",
       " ['Drama'],\n",
       " ['Comedy'],\n",
       " []]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds4 = final_genres.inverse_transform(y_pred)\n",
    "[list(i) for i in test_preds4][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a73d0771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Drama'],\n",
       " [],\n",
       " ['Drama'],\n",
       " ['Action'],\n",
       " ['Drama'],\n",
       " ['Drama', 'Action'],\n",
       " ['Comedy'],\n",
       " [],\n",
       " ['Comedy'],\n",
       " ['Crime']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds5 = final_genres.inverse_transform(y_pred5)\n",
    "[list(i) for i in test_preds5][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f01352d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Documentary'],\n",
       " ['Documentary'],\n",
       " ['Drama'],\n",
       " [],\n",
       " ['Comedy'],\n",
       " ['Drama', 'Action', 'Crime'],\n",
       " ['Comedy', 'Romance'],\n",
       " ['Comedy', 'Adventure'],\n",
       " ['Drama', 'Comedy', 'Romance'],\n",
       " ['Action']]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds6 = final_genres.inverse_transform(y_test)\n",
    "[list(i) for i in test_preds6][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11d59f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
